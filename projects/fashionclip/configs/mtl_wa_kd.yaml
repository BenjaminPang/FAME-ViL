# FashionIQ data nums: 18000
# FashionGen data nums: 60147

includes:
- ./fashioniq_dataset_cfg.yaml
- ./fashiongen_dataset_cfg.yaml
- ./fashiongen_cls_dataset_cfg.yaml
- ./fashiongen_cap_dataset_cfg.yaml

model_config:
  fashionclip:
    training_head_type: mtl-kd
    tasks:
    - itc
    - tgir
    - scr
    - cap
    clip_config:
      clip_model_name: openai/clip-vit-base-patch16
    adapter_config:
      freeze: false
      adapter_name: scaled_pa
      bottleneck: 64
      dropout: 0.2
      enable_xattn: true
      share_cross: false
      share_adapter: false
      cross_dropout: 0.2
      adapter_name_list:
      - itc
      - tgir
      - scr
      - cap
    lr_multiplier: 100
    num_labels: 121
    decoding_algorithm: greedy
    learnable_balances: false
    itc_teacher_config:
      training_head_type: mtl
      clip_config:
        clip_model_name: openai/clip-vit-base-patch16
      adapter_config:
        freeze: false
        adapter_name: scaled_pa
        bottleneck: 64
        dropout: 0.0
        enable_xattn: false
        share_cross: false
        share_adapter: false
        cross_dropout: 0.0
      tasks:
      - itc
      pretrained_path: save/fashionclip_fashiongen_itc_alltrain/fashionclip_final.pth
    tgir_teacher_config:
      training_head_type: mtl
      clip_config:
        clip_model_name: openai/clip-vit-base-patch16
      adapter_config:
        freeze: false
        adapter_name: scaled_pa
        bottleneck: 64
        dropout: 0.0
        enable_xattn: true
        share_cross: false
        share_adapter: false
        cross_dropout: 0.0
      tasks:
      - tgir
      pretrained_path: save/fashionclip_fashioniq_composition_alltrain_xattn/fashionclip_final.pth
    scr_teacher_config:
      training_head_type: mtl
      clip_config:
        clip_model_name: openai/clip-vit-base-patch16
      adapter_config:
        freeze: false
        adapter_name: scaled_pa
        bottleneck: 64
        dropout: 0.0
        enable_xattn: true
        share_cross: false
        share_adapter: false
        cross_dropout: 0.0
      tasks:
      - scr
      num_labels: 121
      pretrained_path: save/fashionclip_fashiongen_scr_alltrain_xattn/fashionclip_final.pth
    cap_teacher_config:
      training_head_type: mtl
      clip_config:
        clip_model_name: openai/clip-vit-base-patch16
      adapter_config:
        freeze: false
        adapter_name: scaled_pa
        bottleneck: 64
        dropout: 0.0
        enable_xattn: true
        only_textual_xattn: true
        share_cross: false
        share_adapter: false
        cross_dropout: 0.0
      tasks:
      - cap
      decoding_algorithm: greedy
      pretrained_path: save/fashionclip_fashiongen_cap_alltrain/fashionclip_final.pth

scheduler:
  type: multi_step
  params:
    use_warmup: true
    lr_steps:
    - 50000
    - 80000
    lr_ratio: 0.1
    warmup_iterations: 10000
    warmup_factor: 0.25

optimizer:
  type: adam_w
  params:
    lr: 1e-6
    eps: 1e-8
    weight_decay: 1e-5

evaluation:
  metrics:
  - type: r@k_fashioniq
    datasets:
    - fashioniq
  - type: r@k_general
    datasets:
    - fashiongen
  - type: accuracy
    datasets:
    - fashiongen_cls
  - type: macro_f1
    datasets:
    - fashiongen_cls
  - type: bleu4
    datasets:
    - fashiongen_cap

training:
  experiment_name: fashionclip_mtl(itc+tgir+scr+cap)_wa_kd_xattn_dropout
  batch_size: 64
  lr_scheduler: true
  max_updates: 90000
  log_interval: 10
  checkpoint_interval: 1000
  evaluation_interval: 1000
  find_unused_parameters: true
  # update_frequency: 1
  # accumulate_feilds: false
  # buffer_gradients: true
  # gradient_strategy: explicit
  early_stop:
    criteria: fashioniq/r@k_fashioniq/avg
    minimize: false
  wandb:
    enabled: true

run_type: train_val

multitasking:
  enabled: true
  type: size_proportional
