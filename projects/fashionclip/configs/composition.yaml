# FashionIQ data nums: 18000

model_config:
  fashionclip:
    training_head_type: composition
    clip_config:
      clip_model_name: openai/clip-vit-base-patch16
    adapter_config:
      freeze: true
      adapter_name: scaled_pa
      bottleneck: 64
      dropout: 0.0
      enable_xattn: true
      cross_dropout: 0.5
    losses:
      - type: bbc_loss

dataset_config:
  fashioniq:
    processors:
      text_processor:
        type: clip_tokenizer
        params:
          tokenizer_config:
            type: openai/clip-vit-base-patch16
      train_image_processor:
        type: torchvision_transforms
        params:
          transforms:
            - type: RandomResizedCrop
              params:
                size: [224, 224]
                scale: [0.8, 1.0]
                ratio: [0.75, 1.3]
            - RandomHorizontalFlip
            - ToTensor
            - type: Normalize
              params:
                mean: [0.48145466, 0.4578275, 0.40821073]
                std: [0.26862954, 0.26130258, 0.27577711]
      eval_image_processor:
        type: torchvision_transforms
        params:
          transforms:
            - type: Resize
              params:
                size: [256, 256]
            - type: CenterCrop
              params:
                size: [224, 224]
            - ToTensor
            - type: Normalize
              params:
                mean: [0.48145466, 0.4578275, 0.40821073]
                std: [0.26862954, 0.26130258, 0.27577711]

scheduler:
  type: multi_step
  params:
    use_warmup: false
    lr_steps:
    - 4000
    lr_ratio: 0.1
    warmup_iterations: 2810
    warmup_factor: 0.25

optimizer:
  type: adam_w
  params:
    lr: 1e-4
    eps: 1e-8
    weight_decay: 0.0

evaluation:
  metrics:
    - r@k_fashioniq

training:
  experiment_name: fashionclip_fashioniq_composition_cross_0.5
  batch_size: 64
  lr_scheduler: true
  max_updates: 6000
  log_interval: 10
  checkpoint_interval: 5620
  evaluation_interval: 562
  find_unused_parameters: true
  early_stop:
    criteria: fashioniq/r@k_fashioniq/avg
    minimize: false
  wandb:
    enabled: true

run_type: train_val
