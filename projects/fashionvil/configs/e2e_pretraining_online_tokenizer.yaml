# Total data nums:
# BigFACAD: 164438
# FashionGen: 60147
# Fashion200k: 76856
# PolyvoreOutfits: 71967
# Total: 373408

includes:
- configs/models/fashionvil/defaults.yaml

dataset_config:
  big_facad:
    processors:
        masked_image_processor:
          type: blockwise_masked_patch
        masked_token_processor:
          type: fashionvil_text_tokenizer
          params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 75
            do_whole_word_mask: true
  fashiongen:
    processors:
        masked_image_processor:
          type: blockwise_masked_patch
        masked_token_processor:
          type: fashionvil_text_tokenizer
          params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 75
            do_whole_word_mask: true
  fashion200k:
    processors:
        masked_image_processor:
          type: blockwise_masked_patch
        masked_token_processor:
          type: fashionvil_text_tokenizer
          params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 75
            do_whole_word_mask: true
  polyvore_outfits:
    processors:
        masked_image_processor:
          type: blockwise_masked_patch
        masked_token_processor:
          type: fashionvil_text_tokenizer
          params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 75
            do_whole_word_mask: true


model_config:
  fashionvil:
    image_encoder:
      type: torchvision_resnet
      params:
        name: resnet50
        pretrained: true
        zero_init_residual: false
        num_output_features: -1
        pool_type: avg
    image_tokenizer:
      type: vqvae_encoder
      params:
        pretrained_path: ${env.data_dir}/pretrained_models/vqvae_ema_pp_224_7x7_encoder_fashionall.pth
        resolution: 224
        num_tokens: 1024
        codebook_dim: 256
        attn_resolutions: [7]
        hidden_dim: 128
        in_channels: 3
        ch_mult: [1, 1, 2, 2, 4, 4]
        num_res_blocks: 2
        dropout: 0
        z_channels: 256
        double_z: false
    direct_features_input: false
    bypass_transformer: true
    bert_model_name: bert-base-uncased
    training_head_type: pretraining
    task_for_inference: itc
    lr_multiplier: 20
    tasks:
      - itm
      - itc
      - mlm
      - mpfc
    task_probs:
      - 0.25
      - 0.25
      - 0.25
      - 0.25

scheduler:
  type: multi_step
  params:
    use_warmup: true
    lr_steps:
    - 45000
    - 90000
    lr_ratio: 0.1
    warmup_iterations: 7500
    warmup_factor: 0.25

optimizer:
  type: adam_w
  params:
    lr: 1e-5
    eps: 1e-8
    weight_decay: 1e-4

evaluation:
  metrics:
  - type: r@5_rev_retrieval
    datasets:
    - fashiongen
    - fashion200k
    - big_facad
    - polyvore_outfits

training:
  experiment_name: fashionvil_e2e_pretrain_baseline
  batch_size: 256
  lr_scheduler: true
  max_updates: 120000
  log_interval: 10
  checkpoint_interval: 15000
  evaluation_interval: 1500
  early_stop:
    criteria: fashiongen/r@5_rev_retrieval
    minimize: false
  wandb:
    enabled: true

run_type: train_val
