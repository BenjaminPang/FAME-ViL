# FashionIQ data nums: 18000

includes:
- ./e2e_composition.yaml

model_config:
  fashionvil:
    image_encoder:
      type: vit_image_encoder
      params:
        name: vit
        pretrained_model_name: google/vit-base-patch16-224-in21k
        random_init: false
        gradient_checkpointing: false
    visual_embedding_dim: 768
    lr_multiplier: 1

training:
  experiment_name: fashionvil_composition_fashioniq_e2e_pretrain_vit

checkpoint:
  resume_pretrained: true
  resume_file: save/fashionvil_e2e_pretrain_final_vit16/best.ckpt
  pretrained_state_mapping:
    image_encoder: image_encoder
    model.bert: model.bert
